{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2ef3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Imports ----\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a78ca5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uber_scaler.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Data Preparation ----\n",
    "df = pd.read_csv(\"UBER.csv\")\n",
    "scaler = MinMaxScaler()\n",
    "df[\"Close_scaled\"] = scaler.fit_transform(df[[\"Close\"]])\n",
    "joblib.dump(scaler, \"uber_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ff0339",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10\n",
    "X, y = [], []\n",
    "for i in range(len(df) - n_steps):\n",
    "    X.append(df[\"Close_scaled\"].values[i:i+n_steps])\n",
    "    y.append(df[\"Close_scaled\"].values[i+n_steps])\n",
    "X, y = np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc25e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1170ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Quantum Circuit ----\n",
    "n_qubits = 4  # we’ll use only 4 time steps as features\n",
    "n_layers = 3\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc919271",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def circuit(inputs, weights):\n",
    "    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f11fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Torch Model ----\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}\n",
    "qlayer = qml.qnn.TorchLayer(circuit, weight_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c745dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qlayer outputs shape: [batch_size, 1]\n",
    "model = nn.Sequential(qlayer)  # no need for Linear(1,1) now\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dfdb76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Convert Data ----\n",
    "X_train_t = torch.tensor(X_train[:, :n_qubits], dtype=torch.float32)  # trim to 4 features\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c532b6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Madeehah\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:616: UserWarning: Using a target size (torch.Size([572, 1])) that is different to the input size (torch.Size([572])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Loss: 0.205801\n",
      "Epoch 10/20, Loss: 0.162371\n",
      "Epoch 15/20, Loss: 0.123867\n",
      "Epoch 20/20, Loss: 0.094370\n"
     ]
    }
   ],
   "source": [
    "# ---- Train Loop ----\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train_t)\n",
    "    loss = loss_fn(output, y_train_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "262305b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Quantum model weights saved as uber_qnn_model.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"uber_qnn_model.pt\")\n",
    "print(\"✅ Quantum model weights saved as uber_qnn_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c00081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
